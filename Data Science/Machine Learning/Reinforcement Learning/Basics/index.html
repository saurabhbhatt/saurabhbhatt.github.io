



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.1, mkdocs-material-2.2.0">
    
    
      
        <title>Basics of Reinforcement Learning - Machine Learning with Python</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.5d3fffba.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.fbd935c7.css">
      
    
    
      <script src="../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="indigo" data-md-color-accent="indigo">
    
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../.." title="Machine Learning with Python" class="md-header-nav__button md-logo">
          
            <i class="md-icon">memory</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Machine Learning with Python
              </span>
              <span class="md-header-nav__topic">
                Basics of Reinforcement Learning
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon">memory</i>
      
    </span>
    Machine Learning with Python
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Preface" class="md-nav__link">
      Preface
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Part 1: The Fundamentals of Machine Learning
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Part 1: The Fundamentals of Machine Learning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Fundamentals of Machine Learning/Classification/" title="Chapter 3: Classification" class="md-nav__link">
      Chapter 3: Classification
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Fundamentals of Machine Learning/Training Models/" title="Chapter 4: Training Models" class="md-nav__link">
      Chapter 4: Training Models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../Fundamentals of Machine Learning/Support Vector Machines/" title="Chapter 5: Support Vector Machines" class="md-nav__link">
      Chapter 5: Support Vector Machines
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Part 2: Reinforcement Learning
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Part 2: Reinforcement Learning
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Basics of Reinforcement Learning
      </label>
    
    <a href="./" title="Basics of Reinforcement Learning" class="md-nav__link md-nav__link--active">
      Basics of Reinforcement Learning
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#maximizing-future-rewards" title="Maximizing Future Rewards" class="md-nav__link">
    Maximizing Future Rewards
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#q-learning" title="Q-Learning" class="md-nav__link">
    Q-Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-deep-q-network-as-a-q-function" title="The deep Q-network as a Q-function" class="md-nav__link">
    The deep Q-network as a Q-function
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#balancing-exploration-with-exploitation" title="Balancing Exploration with Exploitation" class="md-nav__link">
    Balancing Exploration with Exploitation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experience-replay-or-the-value-of-experience" title="Experience replay, or the value of experience" class="md-nav__link">
    Experience replay, or the value of experience
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Part 3: Time Series
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Part 3: Time Series
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Time Series/Basics of Time Series/" title="Basics of Time Series" class="md-nav__link">
      Basics of Time Series
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Part 4: Recommendation Engine
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Part 4: Recommendation Engine
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../Recommendation Engine/Collaborative Filtering/" title="Collaborative Filtering" class="md-nav__link">
      Collaborative Filtering
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#maximizing-future-rewards" title="Maximizing Future Rewards" class="md-nav__link">
    Maximizing Future Rewards
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#q-learning" title="Q-Learning" class="md-nav__link">
    Q-Learning
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-deep-q-network-as-a-q-function" title="The deep Q-network as a Q-function" class="md-nav__link">
    The deep Q-network as a Q-function
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#balancing-exploration-with-exploitation" title="Balancing Exploration with Exploitation" class="md-nav__link">
    Balancing Exploration with Exploitation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#experience-replay-or-the-value-of-experience" title="Experience replay, or the value of experience" class="md-nav__link">
    Experience replay, or the value of experience
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="basics-of-reinforcement-learning">Basics of Reinforcement Learning</h1>
<p>A single game is one episode of this process, and is represented by a finite sequence of states, actions and rewards:</p>
<span>\[s_0 , a_0 , r_1 , s_1 , a_1 , r_2 , s_2 , \dots , s_{n-1} , a_{n-1} , r_n , s_n\]</span><p>Since, this is a markov decision process, the probability of state <span>\(s_{t+1}\)</span> depends only on current state <span>\(s_t\)</span>
and action <span>\(a_t\)</span>.</p>
<h2 id="maximizing-future-rewards">Maximizing Future Rewards</h2>
<p>Suppose we are an agent, our objective will be to maximize the total reward for each game. Total reward can be represented as follows:</p>
<span>\[R = \sum_{i=1}^{n} r_{i}\]</span><p>In order to maximize the total reward, the agent should try to maximize the total reward starts at any time point <span>\(t\)</span> in the game. The total reward at time step <span>\(t\)</span> is given by <span>\(R_t\)</span> and is represented as:</p>
<span>\[R_t = \sum_{i=t}^{n} r_{i} = r_t + r_{t+1} + \dots + r_n\]</span><p>The reason we are maximizing the future reward is that we can't change the reward which we already get in the past and that is why maximization of future rewards is the only option to maximize the total reward.</p>
<p>However, it is harder to predict the value of the rewards as we go further into the future. In order to take this into consideration, our agent should try to maximize the total discounted future reward at time <span>\(t\)</span> instead. This is done by discounting the reward at each future time step by a factor <span>\(\gamma\)</span> over the previous time step. </p>
<ul>
<li>If <span>\(\gamma = 0\)</span>, then our network does not consider future rewards at all, and </li>
<li>if <span>\(\gamma = 1\)</span>, then our network is completely deterministic. </li>
</ul>
<p>A good value for <span>\(\gamma\)</span> is around 0.9. Factoring the equation allows us to express the total discounted future reward at a given time step recursively as the sum of the current reward and the total discounted future reward at the next time step:</p>
<span>\[\begin{split}
R_t &amp; = r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + \dots + \gamma^{n-t} r_n \\ &amp; = r_t + \gamma (r_{t+1} + \gamma (r_{t+2} + \dots))  \\ &amp; = r_t + \gamma R_{t+1}
\end{split}\]</span><h2 id="q-learning">Q-Learning</h2>
<p>Deep reinforcement learning utilizes a model-free reinforcement learning technique called Q-learning. Q-learning can be used to find an optimal action for any given state in a finite markov decision process. Q-learning tries to maximize the value of the Q-function which represents the maximum discounted future reward when we perform action a in state s:</p>
<span>\[Q(s_t, a_t) = max(R_{t+1})\]</span><p>We can define the Q-function for a transition point <span>\((s_t , a_t , r_t , s_{t+1} )\)</span> in terms of the Q-function at the next
point <span>\((s_{t+1} , a_{t+1} , r_{t+1} , s_{t+2} )\)</span> similar to how we did with the total discounted future reward. This
equation is known as the <strong>Bellman equation</strong>:</p>
<span>\[Q(s_t, a_t) = r_t + \gamma max_{a_{t+1}} Q(s_{t+1}, a_{t+1})\]</span><h2 id="the-deep-q-network-as-a-q-function">The deep Q-network as a Q-function</h2>
<h2 id="balancing-exploration-with-exploitation">Balancing Exploration with Exploitation</h2>
<p>Deep reinforcement learning is an example of online learning, where the training and prediction steps are interspersed. </p>
<p>Unlike batch learning techniques where the best predictor is generated by learning on the entire training data, a predictor trained with online learning is continuously improving as it trains on new data. That is the reason that in the initial epochs of training, a deep Q-network gives random predictions which can give rise to poor Q-learning performance. </p>
<p>To alleviate this, we can use a simple exploration method such as <span>\(\epsilon -greedy\)</span>. In case of <span>\(\epsilon -greedy\)</span> exploration, the agent chooses the action suggested by the network with probability <span>\(1 - \epsilon\)</span> or an action uniformly at random otherwise. That is why this strategy is called exploration/exploitation.</p>
<p>As the number of epochs increases and the Q-function converges, it begins to return more consistent Q-values. The value of <span>\(\epsilon\)</span> can be attenuated to account for this, so as the network begins to return more consistent predictions, the agent chooses to exploit the values returned by the network over choosing random actions. </p>
<p>In case of DeepMind, the value of <span>\(\epsilon\)</span> decreases over time from 1 to 0.1, and in our example it decreases from 0.1 to 0.001. Thus, <span>\(\epsilon -greedy\)</span> exploration ensures that in the beginning the system balances the unreliable predictions made from the Q-network with completely random moves to explore the state space, and then settles down to less aggressive exploration (and more aggressive exploitation) as the predictions made by the Q-network improve.</p>
<h2 id="experience-replay-or-the-value-of-experience">Experience replay, or the value of experience</h2>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../Fundamentals of Machine Learning/Support Vector Machines/" title="Chapter 5: Support Vector Machines" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Chapter 5: Support Vector Machines
              </span>
            </div>
          </a>
        
        
          <a href="../../Time Series/Basics of Time Series/" title="Basics of Time Series" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Basics of Time Series
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2017 Saurabh Bhatt
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.1",url:{base:"../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
    
      
    
  </body>
</html>